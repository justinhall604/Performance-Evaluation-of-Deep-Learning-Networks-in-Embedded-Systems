model_1c32_f_d10
Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv1d (Conv1D)             (None, 28, 32)            928       
                                                                 
 flatten_2 (Flatten)         (None, 896)               0         
                                                                 
 dense_2 (Dense)             (None, 10)                8970      
                                                                 
=================================================================
Total params: 9898 (38.66 KB)
Trainable params: 9898 (38.66 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
loss [0.3508310914039612, 0.17332306504249573, 0.14400714635849, 0.129594087600708, 0.11962072551250458, 0.11195273697376251, 0.10683583468198776, 0.1017705425620079, 0.09731315821409225, 0.09385935217142105]
accuracy [0.9018166661262512, 0.9490333199501038, 0.9571333527565002, 0.9621666669845581, 0.9639833569526672, 0.9671000242233276, 0.9682333469390869, 0.969083309173584, 0.9708666801452637, 0.972000002861023]
val_loss [0.19831320643424988, 0.15875442326068878, 0.13988985121250153, 0.13244083523750305, 0.1265120655298233, 0.12321959435939789, 0.12949126958847046, 0.12189093232154846, 0.12144728004932404, 0.12298379093408585]
val_accuracy [0.9429000020027161, 0.9538000226020813, 0.960099995136261, 0.9611999988555908, 0.9623000025749207, 0.9627000093460083, 0.9599999785423279, 0.9643999934196472, 0.9645000100135803, 0.965499997138977]
{'optimizer': 'adam', 'loss': 'sparse_categorical_crossentropy', 'metrics': ['accuracy'], 'loss_weights': None, 'weighted_metrics': None, 'run_eagerly': None, 'steps_per_execution': None, 'jit_compile': None}
Results
Model Loss: 0.12298379093408585
Model Accuracy: 0.965499997138977
Model Size: 145744 Bytes
tflite model size: 42032 Bytes
